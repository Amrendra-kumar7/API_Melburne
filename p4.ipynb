{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 2 fetched. Total users fetched so far: 100\n",
      "Page 3 fetched. Total users fetched so far: 200\n",
      "Page 4 fetched. Total users fetched so far: 300\n",
      "Page 5 fetched. Total users fetched so far: 331\n",
      "User data has been written to users.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "\n",
    "# GitHub API token for authentication (replace with your token)\n",
    "headers = {\n",
    "    'Authorization': 'token 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'\n",
    "}\n",
    "\n",
    "# Prepare the users.csv file\n",
    "with open('users.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['login', 'name', 'company', 'location', 'email', 'hireable', 'bio', \n",
    "                  'public_repos', 'followers', 'following', 'created_at']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    page = 1\n",
    "    users_fetched = 0\n",
    "    \n",
    "    while True:\n",
    "        # Fetch users from the GitHub API for each page\n",
    "        url = f'https://api.github.com/search/users?q=location:melbourne+followers:>100&per_page=100&page={page}'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        users_data = response.json()\n",
    "\n",
    "        if 'items' not in users_data or not users_data['items']:\n",
    "            # If no more users are returned, break out of the loop\n",
    "            break\n",
    "\n",
    "        for user in users_data['items']:\n",
    "            # Fetch detailed user info\n",
    "            user_data = requests.get(user['url'], headers=headers).json()\n",
    "\n",
    "            # Clean company names\n",
    "            cleaned_company = user_data.get('company', '')\n",
    "            if cleaned_company:\n",
    "                cleaned_company = cleaned_company.strip().lstrip('@').upper()\n",
    "\n",
    "            # Write user info to CSV\n",
    "            writer.writerow({\n",
    "                'login': user_data.get('login'),\n",
    "                'name': user_data.get('name'),\n",
    "                'company': cleaned_company,\n",
    "                'location': user_data.get('location'),\n",
    "                'email': user_data.get('email'),\n",
    "                'hireable': 'true' if user_data.get('hireable') else 'false',\n",
    "                'bio': user_data.get('bio'),\n",
    "                'public_repos': user_data.get('public_repos'),\n",
    "                'followers': user_data.get('followers'),\n",
    "                'following': user_data.get('following'),\n",
    "                'created_at': user_data.get('created_at')\n",
    "            })\n",
    "\n",
    "        # Increment page number for pagination\n",
    "        page += 1\n",
    "        users_fetched += len(users_data['items'])\n",
    "\n",
    "        print(f'Page {page} fetched. Total users fetched so far: {users_fetched}')\n",
    "\n",
    "print(\"User data has been written to users.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the repositories.csv file\n",
    "with open('repositories.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['login', 'full_name', 'created_at', 'stargazers_count', \n",
    "                  'watchers_count', 'language', 'has_projects', 'has_wiki', 'license_name']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Read users.csv and fetch repositories for each user\n",
    "    with open('users.csv', newline='', encoding='utf-8') as usersfile:\n",
    "        users_reader = csv.DictReader(usersfile)\n",
    "\n",
    "        for user in users_reader:\n",
    "            user_login = user['login']\n",
    "            url = f'https://api.github.com/users/{user_login}/repos?per_page=500'\n",
    "            response = requests.get(url, headers=headers)\n",
    "            repos_data = response.json()\n",
    "\n",
    "            for repo in repos_data:\n",
    "                writer.writerow({\n",
    "                    'login': user_login,\n",
    "                    'full_name': repo.get('full_name'),\n",
    "                    'created_at': repo.get('created_at'),\n",
    "                    'stargazers_count': repo.get('stargazers_count'),\n",
    "                    'watchers_count': repo.get('watchers_count'),\n",
    "                    'language': repo.get('language'),\n",
    "                    'has_projects': repo.get('has_projects'),\n",
    "                    'has_wiki': repo.get('has_wiki'),\n",
    "                    'license_name': repo['license']['key'] if repo.get('license') else None\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 users in Melbourne with the highest number of followers:\n",
      "mosh-hamedani, TheCherno, haileys, rstacruz, jesseduffield\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Sort the DataFrame by the number of followers in descending order\n",
    "top_users = users_df.sort_values(by='followers', ascending=False).head(5)\n",
    "\n",
    "# Extract the login values of the top 5 users\n",
    "top_logins = top_users['login'].tolist()\n",
    "\n",
    "# Create a comma-separated string of logins\n",
    "top_logins_str = ', '.join(top_logins)\n",
    "\n",
    "print(\"Top 5 users in Melbourne with the highest number of followers:\")\n",
    "print(top_logins_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 earliest registered GitHub users in Melbourne:\n",
      "toolmantim, crafterm, dgoodlad, Sutto, mdub\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Convert the created_at column to datetime for proper sorting\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "\n",
    "# Sort the DataFrame by the created_at column in ascending order\n",
    "earliest_users = users_df.sort_values(by='created_at').head(5)\n",
    "\n",
    "# Extract the login values of the 5 earliest users\n",
    "earliest_logins = earliest_users['login'].tolist()\n",
    "\n",
    "# Create a comma-separated string of logins\n",
    "earliest_logins_str = ', '.join(earliest_logins)\n",
    "\n",
    "print(\"5 earliest registered GitHub users in Melbourne:\")\n",
    "print(earliest_logins_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'license_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\amren\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'license_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m users_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Filter out rows with missing license names\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m filtered_licenses \u001b[38;5;241m=\u001b[39m users_df[\u001b[43musers_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlicense_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Count the occurrences of each license name\u001b[39;00m\n\u001b[0;32m     10\u001b[0m license_counts \u001b[38;5;241m=\u001b[39m filtered_licenses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlicense_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32mc:\\Users\\amren\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\amren\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'license_name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Filter out rows with missing license names\n",
    "filtered_licenses = users_df[users_df['license_name'].notnull()]\n",
    "\n",
    "# Count the occurrences of each license name\n",
    "license_counts = filtered_licenses['license_name'].value_counts()\n",
    "\n",
    "# Get the top 3 most popular licenses\n",
    "top_licenses = license_counts.head(3)\n",
    "\n",
    "# Create a comma-separated string of the top license names\n",
    "top_licenses_str = ', '.join(top_licenses.index)\n",
    "\n",
    "print(\"3 most popular licenses among users in Melbourne:\")\n",
    "print(top_licenses_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['login', 'full_name', 'created_at', 'stargazers_count',\n",
      "       'watchers_count', 'language', 'has_projects', 'has_wiki',\n",
      "       'license_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Print the column names\n",
    "print(users_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['login', 'full_name', 'created_at', 'stargazers_count',\n",
      "       'watchers_count', 'language', 'has_projects', 'has_wiki',\n",
      "       'license_name'],\n",
      "      dtype='object')\n",
      "3 most popular licenses among users in Melbourne:\n",
      "mit, other, apache-2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories.csv file\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Check the column names to verify\n",
    "print(repositories_df.columns)\n",
    "\n",
    "# Filter out rows with missing license names\n",
    "filtered_licenses = repositories_df[repositories_df['license_name'].notnull()]\n",
    "\n",
    "# Count the occurrences of each license name\n",
    "license_counts = filtered_licenses['license_name'].value_counts()\n",
    "\n",
    "# Get the top 3 most popular licenses\n",
    "top_licenses = license_counts.head(3)\n",
    "\n",
    "# Create a comma-separated string of the top license names\n",
    "top_licenses_str = ', '.join(top_licenses.index)\n",
    "\n",
    "print(\"3 most popular licenses among users in Melbourne:\")\n",
    "print(top_licenses_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority of developers work at: MONASH UNIVERSITY (Count: 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Clean the company names\n",
    "def clean_company(company):\n",
    "    if pd.isna(company):\n",
    "        return None  # Return None for missing company names\n",
    "    return company.strip().lstrip('@').upper()  # Trim whitespace, remove @, convert to uppercase\n",
    "\n",
    "# Apply the cleaning function to the company column\n",
    "users_df['cleaned_company'] = users_df['company'].apply(clean_company)\n",
    "\n",
    "# Count the occurrences of each cleaned company name\n",
    "company_counts = users_df['cleaned_company'].value_counts()\n",
    "\n",
    "# Get the company with the highest count\n",
    "top_company = company_counts.idxmax()\n",
    "top_company_count = company_counts.max()\n",
    "\n",
    "print(f\"The majority of developers work at: {top_company} (Count: {top_company_count})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most popular programming language among users in Melbourne is: JavaScript (Count: 3504)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories.csv file\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Count the occurrences of each programming language\n",
    "language_counts = repositories_df['language'].value_counts()\n",
    "\n",
    "# Get the most popular programming language\n",
    "most_popular_language = language_counts.idxmax()\n",
    "most_popular_language_count = language_counts.max()\n",
    "\n",
    "print(f\"The most popular programming language among users in Melbourne is: {most_popular_language} (Count: {most_popular_language_count})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second most popular programming language among users who joined after 2020 is: JavaScript (Count: 29)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Convert the created_at column to datetime\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "\n",
    "# Filter users who joined after 2020\n",
    "filtered_users = users_df[users_df['created_at'] > '2020-01-01']\n",
    "\n",
    "# Load the repositories.csv file\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Merge the filtered users with repositories based on login\n",
    "merged_df = repositories_df[repositories_df['login'].isin(filtered_users['login'])]\n",
    "\n",
    "# Count the occurrences of each programming language for the filtered users\n",
    "language_counts = merged_df['language'].value_counts()\n",
    "\n",
    "# Get the second most popular programming language\n",
    "if len(language_counts) >= 2:\n",
    "    second_most_popular_language = language_counts.index[1]  # Second most popular\n",
    "    second_most_popular_language_count = language_counts.iloc[1]  # Count of the second most popular\n",
    "else:\n",
    "    second_most_popular_language = None\n",
    "    second_most_popular_language_count = 0\n",
    "\n",
    "print(f\"The second most popular programming language among users who joined after 2020 is: {second_most_popular_language} (Count: {second_most_popular_language_count})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The programming language with the highest average number of stars per repository is: D (Average Stars: 2516.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories.csv file\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Group by language and calculate the average number of stars\n",
    "average_stars_per_language = repositories_df.groupby('language')['stargazers_count'].mean()\n",
    "\n",
    "# Get the language with the highest average number of stars\n",
    "highest_average_language = average_stars_per_language.idxmax()\n",
    "highest_average_stars = average_stars_per_language.max()\n",
    "\n",
    "print(f\"The programming language with the highest average number of stars per repository is: {highest_average_language} (Average Stars: {highest_average_stars})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 users in terms of leader_strength are: mosh-hamedani, binarythistle, TheCherno, TuPayChain, rogerclarkmelbourne\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate leader_strength\n",
    "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
    "\n",
    "# Sort by leader_strength in descending order and select the top 5\n",
    "top_users = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
    "\n",
    "# Extract their logins\n",
    "top_user_logins = top_users['login'].tolist()\n",
    "\n",
    "# Join the logins into a comma-separated string\n",
    "top_user_logins_string = ', '.join(top_user_logins)\n",
    "\n",
    "print(f\"The top 5 users in terms of leader_strength are: {top_user_logins_string}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the number of followers and the number of public repositories is: 0.188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate the correlation between followers and public repositories\n",
    "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"The correlation between the number of followers and the number of public repositories is: {correlation:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression slope of followers on public repositories is: 2.242\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(users_df['public_repos'], users_df['followers'])\n",
    "\n",
    "# Print the slope rounded to 3 decimal places\n",
    "print(f\"The regression slope of followers on public repositories is: {slope:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between having projects enabled and having wiki enabled is: 0.409\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories.csv file\n",
    "repos_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert boolean columns to numeric (1 for True, 0 for False)\n",
    "repos_df['has_projects'] = repos_df['has_projects'].astype(int)\n",
    "repos_df['has_wiki'] = repos_df['has_wiki'].astype(int)\n",
    "\n",
    "# Calculate the correlation between having projects enabled and having wiki enabled\n",
    "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"The correlation between having projects enabled and having wiki enabled is: {correlation:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average following per user for hireable users minus the average following for non-hireable users is: -46.243\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate average following for hireable users\n",
    "avg_following_hireable = users_df[users_df['hireable'] == True]['following'].mean()\n",
    "\n",
    "# Calculate average following for non-hireable users\n",
    "avg_following_non_hireable = users_df[users_df['hireable'] == False]['following'].mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = avg_following_hireable - avg_following_non_hireable\n",
    "\n",
    "# Print the result rounded to 3 decimal places\n",
    "print(f\"The average following per user for hireable users minus the average following for non-hireable users is: {difference:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression slope of followers on bio length is: 1.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amren\\AppData\\Local\\Temp\\ipykernel_28448\\3051487244.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_with_bios['bio_length'] = users_with_bios['bio'].apply(len)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Filter out users without bios\n",
    "users_with_bios = users_df[users_df['bio'].notnull()]\n",
    "\n",
    "# Calculate the length of the bio in Unicode characters\n",
    "users_with_bios['bio_length'] = users_with_bios['bio'].apply(len)\n",
    "\n",
    "# Define the dependent and independent variables\n",
    "X = users_with_bios['bio_length']  # Independent variable (bio length)\n",
    "y = users_with_bios['followers']    # Dependent variable (followers)\n",
    "\n",
    "# Add a constant to the independent variable for the regression model\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform the regression\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the slope (coefficient) of the bio length\n",
    "slope = model.params['bio_length']\n",
    "\n",
    "# Print the slope rounded to 3 decimal places\n",
    "print(f\"The regression slope of followers on bio length is: {slope:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 users who created the most repositories on weekends are: xaviershay, md-5, wolfeidau, timbertson, evgenyneu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories.csv file\n",
    "repos_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert 'created_at' column to datetime\n",
    "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
    "\n",
    "# Filter repositories created on weekends (Saturday = 5, Sunday = 6)\n",
    "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
    "\n",
    "# Group by user login and count the number of repositories\n",
    "top_users = weekend_repos.groupby('login').size().reset_index(name='repo_count')\n",
    "\n",
    "# Sort by the number of repositories in descending order\n",
    "top_users_sorted = top_users.sort_values(by='repo_count', ascending=False)\n",
    "\n",
    "# Get the top 5 users\n",
    "top_5_users = top_users_sorted.head(5)\n",
    "\n",
    "# Extract the logins and convert to a comma-separated string\n",
    "top_5_logins = ', '.join(top_5_users['login'])\n",
    "\n",
    "# Print the result\n",
    "print(f\"The top 5 users who created the most repositories on weekends are: {top_5_logins}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in the fraction of users with email addresses is: 0.060\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate the total number of hireable users and those with email\n",
    "hireable_users = users_df[users_df['hireable'] == True]\n",
    "non_hireable_users = users_df[users_df['hireable'] == False]\n",
    "\n",
    "# Fraction of hireable users with email\n",
    "fraction_hireable_with_email = hireable_users['email'].notnull().mean()\n",
    "\n",
    "# Fraction of non-hireable users with email\n",
    "fraction_non_hireable_with_email = non_hireable_users['email'].notnull().mean()\n",
    "\n",
    "# Calculate the difference\n",
    "email_difference = fraction_hireable_with_email - fraction_non_hireable_with_email\n",
    "\n",
    "# Print the result rounded to 3 decimal places\n",
    "print(f\"The difference in the fraction of users with email addresses is: {email_difference:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common surname(s): Jackson, Wang\n",
      "Number of users with the most common surname: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users.csv file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Extract surnames (last words in names) and ignore missing names\n",
    "users_df['surname'] = users_df['name'].dropna().str.strip().str.split().str[-1]\n",
    "\n",
    "# Count occurrences of each surname\n",
    "surname_counts = users_df['surname'].value_counts()\n",
    "\n",
    "# Find the maximum count\n",
    "max_count = surname_counts.max()\n",
    "\n",
    "# Get the most common surnames with the maximum count\n",
    "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "\n",
    "# Sort surnames alphabetically\n",
    "most_common_surnames.sort()\n",
    "\n",
    "# Print results\n",
    "print(f\"Most common surname(s): {', '.join(most_common_surnames)}\")\n",
    "print(f\"Number of users with the most common surname: {max_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
